# Readme01 - 프로젝트 아키텍처 개요

## 1. 프로젝트 목적
AI-Meeting-Summarizer는 한국어 회의록 문서를 로컬 환경(CPU 중심)에서 처리하기 위해 설계된 경량 MLOps형 애플리케이션입니다. 핵심 목표는 다음 세 가지입니다.

- 긴 한국어 회의록을 안정적으로 요약
- 회의 발화/문장을 감정 또는 의도 관점으로 분류
- 후속 검색/유사도 분석을 위한 임베딩 벡터 생성

## 2. 상위 아키텍처
시스템은 **2계층 구조**로 구성됩니다.

1. **Python FastAPI 서버 (AI 추론 계층)**
   - Hugging Face 기반 Transformer 모델 로딩
   - `/summarize`, `/classify`, `/embed`, `/report` API 제공
   - 긴 문서 처리 시 Map-Reduce 요약 파이프라인 적용

2. **Node.js 클라이언트 (호출/자동화 계층)**
   - 샘플 스크립트 기반 API 호출
   - CLI 명령으로 빠른 PoC 가능
   - 결과를 Markdown 문서로 저장 가능

## 3. 데이터 흐름 요약

1. 사용자 입력(회의록 텍스트)
2. Node.js 스크립트 또는 브라우저 UI를 통해 FastAPI 호출
3. FastAPI가 요청 유형에 맞는 모델 추론 수행
4. JSON 응답 반환
5. 클라이언트가 콘솔 출력 또는 markdown 파일로 저장

## 4. 설계 의도
- GPU 없는 환경에서도 동작하도록 모델/파이프라인을 보수적으로 구성
- 긴 텍스트 입력에서 생기는 토큰 길이 제한 문제를 서버에서 해결
- API 중심 구조로 향후 웹/모바일/사내 시스템 연동을 쉽게 확장

## 5. 확장 포인트
- 벡터 DB(예: FAISS, Qdrant) 연동을 통한 회의록 RAG
- 인증/인가(JWT, OAuth2) 추가
- 모델 교체(대형 한국어 LLM 또는 사내 파인튜닝 모델)
- 비동기 처리 큐(Celery, Redis) 도입
